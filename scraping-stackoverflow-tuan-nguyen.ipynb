{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics Questions Asked On Stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://stackoverflow.design/assets/img/logos/so/logo-stackoverflow.png\" alt=\"Stackoverflow-logo\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're a coder, you should be familiar with **Stackoverflow**. Almost any problems you may encounter in your code have already been asked and answered on this website. In this project, I will try to gather information about the *most recent* questions of specific tags on this page and summarize them into a table. <br> \n",
    "\n",
    "For each question, the details include: <br>\n",
    "- What is the question headline?\n",
    "- Who asked and answered the question, and what is his/her reputation (*if available*)?\n",
    "- When was the question asked and answered (*if available*)?\n",
    "- How popular is that question? (views, number of answers, number of votes for the question and top answer)\n",
    "- What tags are associated with it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract raw information from [Stackoverflow question pages](https://stackoverflow.com/questions) .\n",
    " * Inspecting the structure of the webpage and analyze its URL's components.\n",
    " * Define functions: Retrieve all data shown on a single page of the website.\n",
    " * Checkpoint: Scrape the data about the 50 most recent bioinformatics questions on <b>Stackoverflow</b>.\n",
    "2. Draw out the fields of interest from the raw data.\n",
    " * Determine the patterns associated with each of the 14 fields of interest: <i>asker's name, asker's reputation, question, tags, time asked, # views, # answers, # votes for the question, has accepted answer, top answerer's name, top answerer's reputation, # votes for the top answer, time of the top answer, link to the question </i> (example below).\n",
    " * Define functions: fetch relevant information from the chunk of raw data and correct their formats, if necessary.\n",
    " * Checkpoint: parsing through the 50 most recent questions (scraped in 1st step) and pull the 14 fields out. \n",
    "3. Automate the process for multiple pages and organize the results into a table\n",
    " * Define functions: create a loop to extract and filter data from multiple pages of the website, then save all results in a csv files.\n",
    " * Checkpoint: create a csv file containing 100 recent bioinformatics questions on <b>Stackoverflow</b>.\n",
    "4. Conclusion\n",
    " * Apply my functions for a different topic.\n",
    " * Summarize what I have accomplished in this project.\n",
    " * Ideas for future work.\n",
    "5. References\n",
    " \n",
    "Here is a glimpse of what our final output would look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/Qkx2NWJ/Output-example.png\" alt=\"Output-example\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be scraping from [Stackoverflow](https://stackoverflow.com/questions). There is an overwhelming number of questions on the website, and each of them is associated with the tags (such as <code>python</code>, <code>machine-learning</code>, etc) that will narrow down the scope of the questions. Not any strings can be a tag, and all possible tags can be found on the [website](https://stackoverflow.com/tags). <br>\n",
    "For this project, I'm specifically interested in bioinformatics questions (the tag is <code>bioinformatics</code>), so I'm using it as the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the website, I identified 2 URL patterns relevant to my objective: <br>\n",
    "- <code>ht&#8203;tps://stackoverflow.com/questions/tagged/**[tag-name]**?tab=newest&page=**[page-number]**&pagesize=50</code>, this URL will show 50 questions with the tag **[tag-name]**, on the page numbered **[page-number]** of all available pages.\n",
    "- <code>ht&#8203;tps://stackoverflow.com/questions/<strong>[question-info]</strong></code>, this URL show the particular question (and answers, if exist) of interest with the relative reference **[question-info]** inside the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to scrape the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions in this section aim to \"copy\" all the HTML content from the website into a variable (in particular, a BeautifulSoup document) for later scraping. <br>\n",
    "These functions, along with those in other sections, will all be integrated for the final purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import requests               # To extract the HTML document from the website\n",
    "from bs4 import BeautifulSoup # To parse through the HTML document\n",
    "import math                   # To round up a division, which is later needed to limit the number of pages that can be scraped\n",
    "import csv                    # To convert result into a csv file\n",
    "import pandas as pd           # To read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the URL\n",
    "def construct_url(topic = None, k = 1, href = None):\n",
    "    base_url = 'https://stackoverflow.com' \n",
    "    if href == None: # First pattern, to find all questions of a tag\n",
    "        url = base_url + '/questions/tagged/' + topic + '?tab=newest&page=' + str(k) + '&pagesize=50'\n",
    "    elif topic == None: # Second pattern, to check a particular question\n",
    "        url = base_url + href\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    # Get the HTML page content using requests\n",
    "    content = requests.get(url)\n",
    "    \n",
    "    # Ensure that the reponse is valid\n",
    "    if content.status_code != 200:\n",
    "        print('Status code:', content.status_code)\n",
    "        raise Exception('The tag may not exist or you have been requesting too frequently')\n",
    "    \n",
    "    # Construct a beautiful soup document\n",
    "    page = BeautifulSoup(content.text, 'html.parser')\n",
    "    \n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm our functions work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the BeautifulSoup document for the tag \"bioinformatics\"\n",
    "url = construct_url(topic = \"bioinformatics\")\n",
    "page = get_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"html__responsive\" lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   Newest 'bioinformatics' Questions - Stack Overflow\n",
      "  </title>\n",
      "  <link href=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/favicon.ico?v=ec617d715196\" rel=\"shortcut icon\"/>\n",
      "  <link href=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\" rel=\"apple-touch-icon\"/>\n",
      "  <link href=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-touch-icon.png?v=c78bd457575a\" rel=\"image_src\"/>\n",
      "  <link href=\"/opensearch.xml\" rel=\"search\" title=\"Stack Overflow\" type=\"application/opensearchdescription+xml\"/>\n",
      "  <meta content=\"width=device-width, height=device-height, initial-scale=1.0, minimum-scale=1.0\" name=\"viewport\"/>\n",
      "  <meta content=\"website\" property=\"og:type\">\n",
      "   <meta content=\"https://stackoverflow.com/questions/tagged/bioinformatics\" property=\"og:url\"/>\n",
      "   <meta content=\"Stack Overflow\" property=\"og:site_name\"/>\n",
      "   <meta content=\"https://cdn.sstatic.net/Sites/stackoverflow/Img/apple-to\n"
     ]
    }
   ],
   "source": [
    "# Inspecting 1000 first character of the HTML page\n",
    "print(page.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details From Each Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the beginning, I want to extract the questions, their indices, askers and answerers. In order to do that, I inspected the fields of interest and identified their HTML tags and attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the page listing all questions, the information about each question is stored within a **\\<div>** tag, with the attribute <code>class='s-post-summary'</code>. They can visualized as <u>blocks</u> separating the questions on the web browser interface. Furthermore, they contain 2 child **\\<div>** tag *content* and *stats*, with <code>class='s-post-summary--content'</code> and <code>class='s-post-summary--stats'</code>, respectively: <br>\n",
    "- *content* tags contain information about the question title, question tags, information of the asker (name and reputation), and when the question was asked. The information are displayed on the <u>right</u> side of the question block.\n",
    "- *stat* tags contain some indices about the question, including the number of votes for the questions, number of answers, number of views, and whether the asker has accepted any answer. The information are displayed on the <u>left</u> side of the question block.\n",
    "\n",
    "The image below is an example of a question block. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/mSxzjfs/block-example.png\" alt=\"Block Example\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *content* is on the right, containing the following information: <br>\n",
    "- Question title: Calculate ratio of values within one column\n",
    "- Tags: r, calculated-columns\n",
    "- Asker: Jorge Cornick, reputation 1\n",
    "- Time the question was asked: 2 hours ago\n",
    "\n",
    "The *stat* is on the left, showing: <br>\n",
    "- 0 votes for the questions, 2 answers and 23 views.\n",
    "- The asker has not accepted any answers (otherwise, the back ground color of <code>2 answers</code> would have been green with a stick next to it).\n",
    "\n",
    "To extract the information, I used the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the *content* tag:\n",
    "\n",
    "|Detail | Tag | Attribute | Other information |\n",
    "|-------|-----|-----------|------------------|\n",
    "|Title  | a   |           |The first 'a' tag   |\n",
    "|Tags   | ul, li|         | |\n",
    "|Asker name|a |class='s-user-card--info'|Some do not have |\n",
    "|Asker reputation|a |class='s-user-card--rep'|Some do not have |\n",
    "|Time asked|time, span| |The first 'span' tag only. Some do not have|\n",
    "\n",
    "For the *stat* tag:\n",
    "\n",
    "|Detail | Tag | Attribute | Other information |\n",
    "|-------|-----|-----------|------------------|\n",
    "|Votes, Answers, Views|span|class='s-post-summary--stats-item-number'|Get 3 numbers in the same order |\n",
    "|Has accepted answer| |class = 'has-accepted-answer'|A boolean value to check if such class exist|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an illustration of how I chose the tags and attributes of each section based on my observation of the HTML link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ibb.co/PW94W2V/HTML-tags.png\" alt=\"HTML-tags\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the question has some answers, I am curious about the top answer (with the most votes, or the most recent if the votes are tied). To scrape that, I enter the [URL of the question](https://stackoverflow.com/questions/74838141/calculate-ratio-of-values-within-one-column), which entail the question itself and all the answers. <br>\n",
    "The page is also designed into blocks (**\\<div>** tag, <code>class='post-layout'</code>), and the top answer is always the second block. Then, I can get the information about the answer using the following parameter:\n",
    "\n",
    "|Detail | Tag | Attribute | Other information |\n",
    "|-------|-----|-----------|------------------|\n",
    "|Answerer name|div, span |class='user-details', itemprop='author' |The attributes are applied for \\<div> tag only. Some do not have |\n",
    "|Asker reputation|span |class='reputation-score'|Some do not have |\n",
    "|Time answered|span|class='user-action-time'|\\<span> is applied after filtered by class|\n",
    "|Votes| |class='js-vote-count'||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Extract Relevant Information from the HTML Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions in this section aim to extract the information from a single page and put it in a list of dictionaries. <br>\n",
    "<b><i>Note </i></b>that these functions use specific tags and attributes on the page as of Dec 20th, 2022, so they may not always work in the future if Stackoverflow changes its design. <br>\n",
    "These functions, along with those in other sections, will all be integrated for the final purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_questions_per_page(page):\n",
    "    # Get list of tags\n",
    "    content_tags = page.find_all('div', {'class': \"s-post-summary--content\"})\n",
    "    stat_tags = page.find_all('div', {'class': \"s-post-summary--stats\"})\n",
    "    \n",
    "    # Lengths of both should be equal\n",
    "    if len(content_tags) != len(stat_tags):\n",
    "        print(len(content_tags), len(stat_tags)) \n",
    "        raise Exception('The number of tags are unequal')\n",
    "    else:\n",
    "        recent_questions = []\n",
    "        for i in range(len(content_tags)):\n",
    "            content_tag = content_tags[i]\n",
    "            stat_tag = stat_tags[i]\n",
    "            # print(i) # Uncomment this for debug\n",
    "            recent_questions.append(parse_info(content_tag, stat_tag))\n",
    "    \n",
    "    return recent_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_info(content_tag, stat_tag):\n",
    "    # Extract question summaries\n",
    "    [question, user_name, user_reputation, other_tags, time_asked] = get_question_info(content_tag)\n",
    "    href = content_tag.find('a')['href']\n",
    "    question_url = construct_url(href=href)\n",
    "    \n",
    "    # Extract question statistics\n",
    "    [no_votes, no_answers, views, accepted] = get_question_stat(stat_tag)\n",
    "\n",
    "    # Extract top answer's info\n",
    "    if no_answers > 0:\n",
    "        [answer_name, answer_repu, answer_vote, answer_time] = get_answer_info(href)\n",
    "    else:\n",
    "        [answer_name, answer_repu, answer_vote, answer_time] = [None]*4\n",
    "    return {\n",
    "        'asker_name': user_name,\n",
    "        'asker_reputation': user_reputation,\n",
    "        'question': question,\n",
    "        'tags': other_tags,\n",
    "        'time_asked': time_asked,\n",
    "        'views': views,\n",
    "        'no_answers': no_answers,\n",
    "        'no_votes_question': no_votes,\n",
    "        'has_accepted_answer': accepted,\n",
    "        'answerer_name': answer_name,\n",
    "        'answerer_reputation': answer_repu,\n",
    "        'no_votes_answer': answer_vote,\n",
    "        'time_answered': answer_time,\n",
    "        'link': question_url\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_info(content_tag):\n",
    "    # Question\n",
    "    question = content_tag.find('a').text\n",
    "    # Asker\n",
    "    user = content_tag.find(class_ = \"s-user-card--info\")\n",
    "    if user.find('a') != None:\n",
    "        user_name = user.find('a').text\n",
    "        if user.find(class_=\"s-user-card--rep\") != None:\n",
    "            user_reputation = user.find(class_=\"s-user-card--rep\").text\n",
    "            user_reputation = int(''.join(filter(str.isdigit, user_reputation)))\n",
    "        else:\n",
    "            user_reputation = None\n",
    "    else:\n",
    "        [user_name, user_reputation] = [None]*2\n",
    "    # Other tags\n",
    "    other_tags = [tag.text for tag in content_tag.find('ul').find_all('li')]\n",
    "    other_tags = str(other_tags).replace(\",\", \"/\") # Convert list to string, replace , to / to write into csv later\n",
    "    # Time asked\n",
    "    if content_tag.find('time').find('span') != None:\n",
    "        time_asked = content_tag.find('time').find('span')['title']\n",
    "    else:\n",
    "        time_asked = None\n",
    "    return [question, user_name, user_reputation, other_tags, time_asked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_stat(stat_tag):\n",
    "    # Votes, Answers, Views\n",
    "    [no_votes, no_answers, views] = [str_to_int(stat.text) for stat in stat_tag.find_all('span', class_ = \"s-post-summary--stats-item-number\")]\n",
    "    \n",
    "    # Has accepted answers\n",
    "    accepted = stat_tag.find(class_ = \"has-accepted-answer\") != None\n",
    "    \n",
    "    return [no_votes, no_answers, views, accepted]\n",
    "\n",
    "# Large numbers have 'k' to substitute for x1000, so this function convert them to a numeric format.\n",
    "def str_to_int(str):\n",
    "    return int(float(str[:-1]) * 1000) if str[-1] == 'k' else int(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_info(href):\n",
    "    # Scrape the question page\n",
    "    sub_url = construct_url(href=href)\n",
    "    sub_page = get_page(sub_url)\n",
    "    \n",
    "    # Check only the top answer\n",
    "    top_answer = sub_page.find_all('div', class_ = \"post-layout\", limit = 2)[1]\n",
    "    # How many votes\n",
    "    answer_vote = top_answer.find(class_ = \"js-vote-count\")['data-value']\n",
    "    # When he/she answered\n",
    "    answer_time = top_answer.find(class_ = \"user-action-time\").find('span')['title']\n",
    "    # Who is he/she  \n",
    "    if top_answer.find('div', {'class': \"user-details\", 'itemprop':\"author\"}) != None:\n",
    "        answer_name = top_answer.find('div', {'class': \"user-details\", 'itemprop':\"author\"}).find('span').text# Name\n",
    "        if top_answer.find('span', class_ = \"reputation-score\") != None:\n",
    "            answer_repu = top_answer.find('span', class_ = \"reputation-score\").text # Reputation\n",
    "            answer_repu = str_to_int(answer_repu.replace(\",\",\"\")) \n",
    "        else:\n",
    "            answer_repu = None\n",
    "    else:\n",
    "        [answer_name, answer_repu] = [None]*2\n",
    "    \n",
    "    return [answer_name, answer_repu, answer_vote, answer_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting information from the first questions page with [bioinformatics] tag\n",
    "recent_questions = scrape_questions_per_page(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recent_questions) # Should have 50 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'asker_name': 'LaLuna Kon',\n",
       "  'asker_reputation': 23,\n",
       "  'question': 'Mean for multiple BigWig files',\n",
       "  'tags': \"['python'/ 'r'/ 'bioinformatics']\",\n",
       "  'time_asked': '2022-12-20 14:35:24Z',\n",
       "  'views': 17,\n",
       "  'no_answers': 0,\n",
       "  'no_votes_question': 0,\n",
       "  'has_accepted_answer': False,\n",
       "  'answerer_name': None,\n",
       "  'answerer_reputation': None,\n",
       "  'no_votes_answer': None,\n",
       "  'time_answered': None,\n",
       "  'link': 'https://stackoverflow.com/questions/74864686/mean-for-multiple-bigwig-files'},\n",
       " {'asker_name': 'ricehound',\n",
       "  'asker_reputation': 3,\n",
       "  'question': 'How to open and close conda environment while running python script? [duplicate]',\n",
       "  'tags': \"['python'/ 'shell'/ 'terminal'/ 'conda'/ 'bioinformatics']\",\n",
       "  'time_asked': '2022-12-20 13:50:34Z',\n",
       "  'views': 24,\n",
       "  'no_answers': 1,\n",
       "  'no_votes_question': 0,\n",
       "  'has_accepted_answer': False,\n",
       "  'answerer_name': 'August Axelsson',\n",
       "  'answerer_reputation': 1,\n",
       "  'no_votes_answer': '-1',\n",
       "  'time_answered': '2022-12-20 14:57:33Z',\n",
       "  'link': 'https://stackoverflow.com/questions/74864119/how-to-open-and-close-conda-environment-while-running-python-script'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the 2 most recent ones\n",
    "recent_questions[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, I have successfully extracted the information from the website <code>*ht&#8203;tps://stackoverflow.com/questions/tagged/**[tag-name]**?tab=newest&page=**[page-number]**&pagesize=50*</code>, with **[tag-name]** = 'bioinformatics' and **[page-number]** = 1. <br>\n",
    "While I can customize the **[tag-name]**, I have not altered the pages to check yet. Since the URL structure is intuitive, I can perform a loop to extract multiple pages. However, since the act of scraping each page involves scraping up to 50 sub-pages, it is **not possible** to scrape more than <u>3 pages</u> at once. <br>\n",
    "In addition, the scraped information is currently stored as a list of dictionaries, which is not easy to read. Thus, I will use another function to save it as a tabular document (csv file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions in this section aim to integrate extracted information from multiple pages and write the final result into a csv file.\n",
    "These functions, along with those in other sections, will all be integrated for the final purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_recent_questions(topic, n=1, skip=0): \n",
    "    # n = number of pages to scrape, skip = number of pages to skip\n",
    "    # By default, scrape only the first page (50 questions)\n",
    "    \n",
    "    # Estimate the limit\n",
    "    url = construct_url(topic = topic, k = 1)\n",
    "    page = get_page(url)\n",
    "    # Get the number of questions\n",
    "    no_questions = int(''.join(filter(str.isdigit, page.find('div', class_=\"fs-body3\").text))) # Keep only the digit from text\n",
    "    no_pages = math.ceil(no_questions/50)\n",
    "    \n",
    "    if skip >= no_pages:\n",
    "        raise Exception('Skip too many pages. There are ' + str(no_pages) + ' pages available')\n",
    "    elif skip + n > no_pages:\n",
    "        n = no_pages - skip\n",
    "        print(\"Not enough questions. Scraping \" + str(n) + \" pages\")\n",
    "    \n",
    "    # Scraping\n",
    "    questions = []\n",
    "    for page_no in range(skip, skip+n):\n",
    "        # Get the website content (bs4 document)\n",
    "        url = construct_url(topic = topic, k = page_no+1)\n",
    "        page = get_page(url)\n",
    "        # Scrape that website\n",
    "        questions += scrape_questions_per_page(page)\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(items, path): # Reference: https://stackoverflow.com/questions/3086973/how-do-i-convert-this-list-of-dictionaries-to-a-csv-file\n",
    "    keys = items[0].keys()\n",
    "\n",
    "    with open(path, 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 3 - Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping questions from the same topic, but on page 2 and 3\n",
    "almost_recent_question = scrape_recent_questions('bioinformatics', 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(almost_recent_question) #Should be 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'asker_name': 'Janie Olver',\n",
       "  'asker_reputation': 1,\n",
       "  'question': 'Problems downloading edgeR - R version 4.0.2',\n",
       "  'tags': \"['r'/ 'bioinformatics'/ 'rna-seq']\",\n",
       "  'time_asked': '2022-11-29 15:21:57Z',\n",
       "  'views': 21,\n",
       "  'no_answers': 0,\n",
       "  'no_votes_question': 0,\n",
       "  'has_accepted_answer': False,\n",
       "  'answerer_name': None,\n",
       "  'answerer_reputation': None,\n",
       "  'no_votes_answer': None,\n",
       "  'time_answered': None,\n",
       "  'link': 'https://stackoverflow.com/questions/74616335/problems-downloading-edger-r-version-4-0-2'},\n",
       " {'asker_name': 'Nickmofoe',\n",
       "  'asker_reputation': 57,\n",
       "  'question': 'How can I print out multiple similar patterns I have matched in perl?',\n",
       "  'tags': \"['regex'/ 'perl'/ 'bioinformatics'/ 'protein-database']\",\n",
       "  'time_asked': '2022-11-29 12:44:46Z',\n",
       "  'views': 61,\n",
       "  'no_answers': 1,\n",
       "  'no_votes_question': 1,\n",
       "  'has_accepted_answer': True,\n",
       "  'answerer_name': 'pmqs',\n",
       "  'answerer_reputation': 2269,\n",
       "  'no_votes_answer': '2',\n",
       "  'time_answered': '2022-11-29 16:04:34Z',\n",
       "  'link': 'https://stackoverflow.com/questions/74614308/how-can-i-print-out-multiple-similar-patterns-i-have-matched-in-perl'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the 2 top answers\n",
    "almost_recent_question[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result to a csv file\n",
    "write_csv(almost_recent_question, \"bioinformatic_almost_recent_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asker_name</th>\n",
       "      <th>asker_reputation</th>\n",
       "      <th>question</th>\n",
       "      <th>tags</th>\n",
       "      <th>time_asked</th>\n",
       "      <th>views</th>\n",
       "      <th>no_answers</th>\n",
       "      <th>no_votes_question</th>\n",
       "      <th>has_accepted_answer</th>\n",
       "      <th>answerer_name</th>\n",
       "      <th>answerer_reputation</th>\n",
       "      <th>no_votes_answer</th>\n",
       "      <th>time_answered</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janie Olver</td>\n",
       "      <td>1</td>\n",
       "      <td>Problems downloading edgeR - R version 4.0.2</td>\n",
       "      <td>['r'/ 'bioinformatics'/ 'rna-seq']</td>\n",
       "      <td>2022-11-29 15:21:57Z</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/74616335/p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nickmofoe</td>\n",
       "      <td>57</td>\n",
       "      <td>How can I print out multiple similar patterns ...</td>\n",
       "      <td>['regex'/ 'perl'/ 'bioinformatics'/ 'protein-d...</td>\n",
       "      <td>2022-11-29 12:44:46Z</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>pmqs</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-11-29 16:04:34Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74614308/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batman</td>\n",
       "      <td>196</td>\n",
       "      <td>How do I make gsea plot with group names label...</td>\n",
       "      <td>['r'/ 'ggplot2'/ 'plot'/ 'bioinformatics']</td>\n",
       "      <td>2022-11-29 07:29:23Z</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>marco</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-08 09:13:05Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74610471/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plnnvkv</td>\n",
       "      <td>541</td>\n",
       "      <td>Remove a substring from lines starting with a ...</td>\n",
       "      <td>['bash'/ 'bioinformatics'/ 'fasta']</td>\n",
       "      <td>2022-11-28 15:06:06Z</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>William Pursell</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-11-28 15:21:02Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74602571/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nickmofoe</td>\n",
       "      <td>57</td>\n",
       "      <td>How can I find a protein sequence from a FASTA...</td>\n",
       "      <td>['regex'/ 'perl'/ 'bioinformatics'/ 'protein-d...</td>\n",
       "      <td>2022-11-28 11:33:07Z</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>pmqs</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-11-28 22:55:50Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74599963/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Raksha</td>\n",
       "      <td>35</td>\n",
       "      <td>Import SNP data into DendroPy for popgen analyses</td>\n",
       "      <td>['python'/ 'bioinformatics'/ 'dendropy']</td>\n",
       "      <td>2022-10-03 21:38:28Z</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/73941081/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>27</td>\n",
       "      <td>Unable to access jar file (installed in a cond...</td>\n",
       "      <td>['java'/ 'bash'/ 'jar'/ 'bioinformatics'/ 'pic...</td>\n",
       "      <td>2022-10-03 15:45:25Z</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>Will Holtz</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-10-04 04:53:18Z</td>\n",
       "      <td>https://stackoverflow.com/questions/73937802/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Programming Noob</td>\n",
       "      <td>1035</td>\n",
       "      <td>Converting a data frame using a formula</td>\n",
       "      <td>['r'/ 'dataframe'/ 'bioinformatics']</td>\n",
       "      <td>2022-10-03 13:54:37Z</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Allan Cameron</td>\n",
       "      <td>122000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-10-03 14:05:40Z</td>\n",
       "      <td>https://stackoverflow.com/questions/73936504/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Shelby Labuschagne</td>\n",
       "      <td>63</td>\n",
       "      <td>Why does my Manhattan plot look like this?</td>\n",
       "      <td>['python'/ 'bioinformatics'/ 'genetics'/ 'gwas...</td>\n",
       "      <td>2022-10-02 14:27:40Z</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/73926611/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nickmofoe</td>\n",
       "      <td>57</td>\n",
       "      <td>Missing command in an R package</td>\n",
       "      <td>['r'/ 'package'/ 'bioinformatics']</td>\n",
       "      <td>2022-10-02 08:25:59Z</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>r2evans</td>\n",
       "      <td>121000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-10-02 09:39:53Z</td>\n",
       "      <td>https://stackoverflow.com/questions/73924382/m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            asker_name  asker_reputation  \\\n",
       "0          Janie Olver                 1   \n",
       "1            Nickmofoe                57   \n",
       "2               batman               196   \n",
       "3              plnnvkv               541   \n",
       "4            Nickmofoe                57   \n",
       "..                 ...               ...   \n",
       "95              Raksha                35   \n",
       "96               Quinn                27   \n",
       "97    Programming Noob              1035   \n",
       "98  Shelby Labuschagne                63   \n",
       "99           Nickmofoe                57   \n",
       "\n",
       "                                             question  \\\n",
       "0        Problems downloading edgeR - R version 4.0.2   \n",
       "1   How can I print out multiple similar patterns ...   \n",
       "2   How do I make gsea plot with group names label...   \n",
       "3   Remove a substring from lines starting with a ...   \n",
       "4   How can I find a protein sequence from a FASTA...   \n",
       "..                                                ...   \n",
       "95  Import SNP data into DendroPy for popgen analyses   \n",
       "96  Unable to access jar file (installed in a cond...   \n",
       "97            Converting a data frame using a formula   \n",
       "98         Why does my Manhattan plot look like this?   \n",
       "99                    Missing command in an R package   \n",
       "\n",
       "                                                 tags            time_asked  \\\n",
       "0                  ['r'/ 'bioinformatics'/ 'rna-seq']  2022-11-29 15:21:57Z   \n",
       "1   ['regex'/ 'perl'/ 'bioinformatics'/ 'protein-d...  2022-11-29 12:44:46Z   \n",
       "2          ['r'/ 'ggplot2'/ 'plot'/ 'bioinformatics']  2022-11-29 07:29:23Z   \n",
       "3                 ['bash'/ 'bioinformatics'/ 'fasta']  2022-11-28 15:06:06Z   \n",
       "4   ['regex'/ 'perl'/ 'bioinformatics'/ 'protein-d...  2022-11-28 11:33:07Z   \n",
       "..                                                ...                   ...   \n",
       "95           ['python'/ 'bioinformatics'/ 'dendropy']  2022-10-03 21:38:28Z   \n",
       "96  ['java'/ 'bash'/ 'jar'/ 'bioinformatics'/ 'pic...  2022-10-03 15:45:25Z   \n",
       "97               ['r'/ 'dataframe'/ 'bioinformatics']  2022-10-03 13:54:37Z   \n",
       "98  ['python'/ 'bioinformatics'/ 'genetics'/ 'gwas...  2022-10-02 14:27:40Z   \n",
       "99                 ['r'/ 'package'/ 'bioinformatics']  2022-10-02 08:25:59Z   \n",
       "\n",
       "    views  no_answers  no_votes_question  has_accepted_answer  \\\n",
       "0      21           0                  0                False   \n",
       "1      61           1                  1                 True   \n",
       "2      30           1                  0                False   \n",
       "3      41           4                  1                 True   \n",
       "4      52           1                  1                 True   \n",
       "..    ...         ...                ...                  ...   \n",
       "95     48           0                  0                False   \n",
       "96    118           1                 -1                 True   \n",
       "97     61           2                  3                False   \n",
       "98     93           0                  0                False   \n",
       "99     45           1                  0                 True   \n",
       "\n",
       "      answerer_name  answerer_reputation  no_votes_answer  \\\n",
       "0               NaN                  NaN              NaN   \n",
       "1              pmqs               2269.0              2.0   \n",
       "2             marco                 41.0              0.0   \n",
       "3   William Pursell             198000.0              1.0   \n",
       "4              pmqs               5003.0              3.0   \n",
       "..              ...                  ...              ...   \n",
       "95              NaN                  NaN              NaN   \n",
       "96       Will Holtz                196.0              1.0   \n",
       "97    Allan Cameron             122000.0              2.0   \n",
       "98              NaN                  NaN              NaN   \n",
       "99          r2evans             121000.0              0.0   \n",
       "\n",
       "           time_answered                                               link  \n",
       "0                    NaN  https://stackoverflow.com/questions/74616335/p...  \n",
       "1   2022-11-29 16:04:34Z  https://stackoverflow.com/questions/74614308/h...  \n",
       "2   2022-12-08 09:13:05Z  https://stackoverflow.com/questions/74610471/h...  \n",
       "3   2022-11-28 15:21:02Z  https://stackoverflow.com/questions/74602571/r...  \n",
       "4   2022-11-28 22:55:50Z  https://stackoverflow.com/questions/74599963/h...  \n",
       "..                   ...                                                ...  \n",
       "95                   NaN  https://stackoverflow.com/questions/73941081/i...  \n",
       "96  2022-10-04 04:53:18Z  https://stackoverflow.com/questions/73937802/u...  \n",
       "97  2022-10-03 14:05:40Z  https://stackoverflow.com/questions/73936504/c...  \n",
       "98                   NaN  https://stackoverflow.com/questions/73926611/w...  \n",
       "99  2022-10-02 09:39:53Z  https://stackoverflow.com/questions/73924382/m...  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glimpse at our table\n",
    "pd.read_csv(\"bioinformatic_almost_recent_questions.csv\") # Should seem legit!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to work. Let's apply to another tag, such as *'mysql'*. Note that we may run into code 406 because we've been requesting too many times. If that happens, wait for about 15 minutes and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the 50 most recent questions with the tag 'mysql'\n",
    "mysql_recent_questions = scrape_recent_questions('mysql', 2, 0)\n",
    "# Write result to a csv file\n",
    "write_csv(mysql_recent_questions, \"mysql_recent_questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asker_name</th>\n",
       "      <th>asker_reputation</th>\n",
       "      <th>question</th>\n",
       "      <th>tags</th>\n",
       "      <th>time_asked</th>\n",
       "      <th>views</th>\n",
       "      <th>no_answers</th>\n",
       "      <th>no_votes_question</th>\n",
       "      <th>has_accepted_answer</th>\n",
       "      <th>answerer_name</th>\n",
       "      <th>answerer_reputation</th>\n",
       "      <th>no_votes_answer</th>\n",
       "      <th>time_answered</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pat Lefebvre</td>\n",
       "      <td>1</td>\n",
       "      <td>MariaDB SQL query help needed</td>\n",
       "      <td>['mysql'/ 'sql'/ 'join'/ 'mariadb'/ 'left-join']</td>\n",
       "      <td>2022-12-20 20:36:58Z</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/74868630/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>momo668</td>\n",
       "      <td>138</td>\n",
       "      <td>SQL on splitting table by column and rejoining...</td>\n",
       "      <td>['mysql'/ 'sql']</td>\n",
       "      <td>2022-12-20 20:28:24Z</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/74868574/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user20826386</td>\n",
       "      <td>1</td>\n",
       "      <td>How to select records with distinct combinatio...</td>\n",
       "      <td>['mysql']</td>\n",
       "      <td>2022-12-20 20:12:31Z</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>Stu</td>\n",
       "      <td>25300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-12-20 20:23:43Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74868441/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osi129</td>\n",
       "      <td>1</td>\n",
       "      <td>I am having problems in installing Mysql in ub...</td>\n",
       "      <td>['mysql']</td>\n",
       "      <td>2022-12-20 20:05:59Z</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/74868382/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrew Ya</td>\n",
       "      <td>1</td>\n",
       "      <td>MySQL error 'Prepared statement needs to be re...</td>\n",
       "      <td>['mysql']</td>\n",
       "      <td>2022-12-20 19:39:06Z</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/74868115/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Dit</td>\n",
       "      <td>1</td>\n",
       "      <td>Mysql Keeps deleting the written ID but the ID...</td>\n",
       "      <td>['php'/ 'html'/ 'mysql'/ 'mysqli']</td>\n",
       "      <td>2022-12-19 23:23:11Z</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>Barmar</td>\n",
       "      <td>157000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-12-20 05:21:52Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74857027/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>darkstar</td>\n",
       "      <td>621</td>\n",
       "      <td>Would indexing a text field allow for better p...</td>\n",
       "      <td>['mysql'/ 'sql'/ 'indexing']</td>\n",
       "      <td>2022-12-19 23:09:16Z</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Chris Maurer</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-12-19 23:41:09Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74856945/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>B.12</td>\n",
       "      <td>9</td>\n",
       "      <td>VARCHAR TO DATETIME</td>\n",
       "      <td>['mysql']</td>\n",
       "      <td>2022-12-19 22:45:01Z</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>False</td>\n",
       "      <td>Barmar</td>\n",
       "      <td>709000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2022-12-19 23:44:23Z</td>\n",
       "      <td>https://stackoverflow.com/questions/74856785/v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Developer Jano</td>\n",
       "      <td>81</td>\n",
       "      <td>Best way to update 10k rows based on ID</td>\n",
       "      <td>['mysql']</td>\n",
       "      <td>2022-12-19 22:36:23Z</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/74856736/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>August HÃ¸g Dedenroth</td>\n",
       "      <td>1</td>\n",
       "      <td>My fetch API keeps returning my JSON data as n...</td>\n",
       "      <td>['javascript'/ 'mysql'/ 'fetch-api']</td>\n",
       "      <td>2022-12-19 21:58:17Z</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://stackoverflow.com/questions/74856455/m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asker_name  asker_reputation  \\\n",
       "0           Pat Lefebvre                 1   \n",
       "1                momo668               138   \n",
       "2           user20826386                 1   \n",
       "3                 osi129                 1   \n",
       "4              Andrew Ya                 1   \n",
       "..                   ...               ...   \n",
       "95                   Dit                 1   \n",
       "96              darkstar               621   \n",
       "97                  B.12                 9   \n",
       "98        Developer Jano                81   \n",
       "99  August HÃ¸g Dedenroth                 1   \n",
       "\n",
       "                                             question  \\\n",
       "0                       MariaDB SQL query help needed   \n",
       "1   SQL on splitting table by column and rejoining...   \n",
       "2   How to select records with distinct combinatio...   \n",
       "3   I am having problems in installing Mysql in ub...   \n",
       "4   MySQL error 'Prepared statement needs to be re...   \n",
       "..                                                ...   \n",
       "95  Mysql Keeps deleting the written ID but the ID...   \n",
       "96  Would indexing a text field allow for better p...   \n",
       "97                                VARCHAR TO DATETIME   \n",
       "98            Best way to update 10k rows based on ID   \n",
       "99  My fetch API keeps returning my JSON data as n...   \n",
       "\n",
       "                                                tags            time_asked  \\\n",
       "0   ['mysql'/ 'sql'/ 'join'/ 'mariadb'/ 'left-join']  2022-12-20 20:36:58Z   \n",
       "1                                   ['mysql'/ 'sql']  2022-12-20 20:28:24Z   \n",
       "2                                          ['mysql']  2022-12-20 20:12:31Z   \n",
       "3                                          ['mysql']  2022-12-20 20:05:59Z   \n",
       "4                                          ['mysql']  2022-12-20 19:39:06Z   \n",
       "..                                               ...                   ...   \n",
       "95                ['php'/ 'html'/ 'mysql'/ 'mysqli']  2022-12-19 23:23:11Z   \n",
       "96                      ['mysql'/ 'sql'/ 'indexing']  2022-12-19 23:09:16Z   \n",
       "97                                         ['mysql']  2022-12-19 22:45:01Z   \n",
       "98                                         ['mysql']  2022-12-19 22:36:23Z   \n",
       "99              ['javascript'/ 'mysql'/ 'fetch-api']  2022-12-19 21:58:17Z   \n",
       "\n",
       "    views  no_answers  no_votes_question  has_accepted_answer answerer_name  \\\n",
       "0       6           0                  0                False           NaN   \n",
       "1      12           0                 -2                False           NaN   \n",
       "2      12           1                 -2                False           Stu   \n",
       "3      12           0                 -4                False           NaN   \n",
       "4      11           0                 -1                False           NaN   \n",
       "..    ...         ...                ...                  ...           ...   \n",
       "95     35           1                 -2                False        Barmar   \n",
       "96     32           3                  1                False  Chris Maurer   \n",
       "97     33           1                 -2                False        Barmar   \n",
       "98     36           0                  1                False           NaN   \n",
       "99     22           0                 -3                False           NaN   \n",
       "\n",
       "    answerer_reputation  no_votes_answer         time_answered  \\\n",
       "0                   NaN              NaN                   NaN   \n",
       "1                   NaN              NaN                   NaN   \n",
       "2               25300.0              0.0  2022-12-20 20:23:43Z   \n",
       "3                   NaN              NaN                   NaN   \n",
       "4                   NaN              NaN                   NaN   \n",
       "..                  ...              ...                   ...   \n",
       "95             157000.0              1.0  2022-12-20 05:21:52Z   \n",
       "96               1644.0              2.0  2022-12-19 23:41:09Z   \n",
       "97             709000.0             -1.0  2022-12-19 23:44:23Z   \n",
       "98                  NaN              NaN                   NaN   \n",
       "99                  NaN              NaN                   NaN   \n",
       "\n",
       "                                                 link  \n",
       "0   https://stackoverflow.com/questions/74868630/m...  \n",
       "1   https://stackoverflow.com/questions/74868574/s...  \n",
       "2   https://stackoverflow.com/questions/74868441/h...  \n",
       "3   https://stackoverflow.com/questions/74868382/i...  \n",
       "4   https://stackoverflow.com/questions/74868115/m...  \n",
       "..                                                ...  \n",
       "95  https://stackoverflow.com/questions/74857027/m...  \n",
       "96  https://stackoverflow.com/questions/74856945/w...  \n",
       "97  https://stackoverflow.com/questions/74856785/v...  \n",
       "98  https://stackoverflow.com/questions/74856736/b...  \n",
       "99  https://stackoverflow.com/questions/74856455/m...  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "pd.read_csv(\"mysql_recent_questions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I <u>wrote Python functions</u> using <i>requests</i> and <i>BeautifulSoup</i> libraries to retrieve details about the most recent topic-specific questions asked on <b>Stackoverflow</b>.\n",
    "- For each question entry, I retrieve additional information if not visible on the summary page by <u>scraping its subpage</u> (in particular, the fields associated with the answer if there is one).\n",
    "- The functions were applied to scrape 100 most recent questions with the \"mysql\" tag and store the <u>result in a tabular format</u> (100 rows x 14 columns), showing the names, reputations of the askers and answerers, time asked and answered, associated tags, and the popularities of those questions and answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement for the functions:\n",
    "- Due to the act of scraping subpages, I am limitted to scraping 2-3 pages at a time. I can optimize it by creating 2 scraping options: <i>general</i> showing only fields which are visible on the summary page, and <i>detail</i> adding information about the answers.\n",
    "- Fetch additional detailed information from each question, such as whether the questions/answers have pictures, code sections, or the number of characters.\n",
    "- Scrape the top results for the searched 'key word' instead of 'tag' by changing the URL structures.\n",
    "\n",
    "Follow up on the scraped data:\n",
    "- Analyze the time between when the question was asked and when it was answered.\n",
    "- Identify the trending topics.\n",
    "- Observe the relationship between the length of the question titles and how often they are viewed/answered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://stackoverflow.com/questions\n",
    "- https://stackoverflow.com/questions/3086973/how-do-i-convert-this-list-of-dictionaries-to-a-csv-file\n",
    "- https://jovian.ai/learn/zero-to-data-analyst-bootcamp/lesson/web-scraping-and-rest-apis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
